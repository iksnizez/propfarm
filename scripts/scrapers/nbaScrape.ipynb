{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eee6c360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last day with games played: 2025-03-13\n",
      "scraping for ['nba', 'nhl'] on ['2025-03-14']\n"
     ]
    }
   ],
   "source": [
    "import nbaScraper as ns\n",
    "import actNetScraper as ans\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "leagues = ['nba', 'nhl']   # None or list ['nba', 'nhl', 'nfl', 'mlb', 'wnba'] # NONE looks for all sports\n",
    "specified =  []  ####specific prop, *****only works with a single league in leagues\n",
    "\n",
    "# day adjustment from today (date of running script), negative = dates into the past\n",
    "dayJump = 0 \n",
    "# date can be a list of dates if multiple need scraping 'YYYY-MM-DD'\n",
    "# default is to only pull today or today + dayJump\n",
    "dates = [(datetime.today() + timedelta(days=dayJump)).strftime('%Y-%m-%d')]\n",
    "#dates = ['2024-01-05']#, '2024-01-06', '2024-01-07', '2024-01-08', '2024-01-09', '2024-01-10', '2024-01-11']\n",
    "\n",
    "database_export = True  # add all scrapes to database\n",
    "store_locally = True    # add all scrapes to class variables\n",
    "season_int = 2025 # int will be the final year of the schedule season\n",
    "season_str = '2024-25'\n",
    "season_type = 'Regular+Season' # ['Regular+Season', 'PlayIn', 'Playoffs']\n",
    "per_mode = 'Totals' #['Totals', 'PerGame']\n",
    "\n",
    "# nba website and basketball referenece scrapers\n",
    "scraper = ns.scraper(\n",
    "    browser_path = '..\\\\..\\\\browser\\\\geckodriver.exe',\n",
    "    database_export = database_export, \n",
    "    store_locally = store_locally,\n",
    "    pymysql_conn_str =  None\n",
    ")\n",
    "# assigns the date of the last time code executed as today\n",
    "today = scraper.meta_data['today_dt']\n",
    "\n",
    "# looks up the actual date for the last regular season game date. this will be used to grab the data for the completed games on the date\n",
    "scraper.get_last_game_date(season = season_str)\n",
    "run_date = scraper.last_game_date\n",
    "dateRange = [\n",
    "    run_date, run_date\n",
    "]\n",
    "\n",
    "prop_scraper = ans.actNetScraper(\n",
    "    browser_path = '..\\\\..\\\\browser\\\\geckodriver.exe',\n",
    "    dates = dates,\n",
    "    leagues = leagues,\n",
    "    database_export = database_export, \n",
    "    store_locally = store_locally,\n",
    "    config_path = '..\\\\..\\\\..\\\\..\\\\Notes-General\\\\config.txt',\n",
    "    second_run = False\n",
    ")\n",
    "\n",
    "# turn to False if issues loading new players\n",
    "#prop_scraper.update_players = False\n",
    "\n",
    "# update the league list to only ones with games today\n",
    "#leagues = prop_scraper.check_for_league_games(date_check = None, update_class_leagues_var = True)\n",
    "print('scraping for', prop_scraper.leagues, 'on', prop_scraper.dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cfc593e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 run date...\n",
      "\n",
      "scraping nba ...\n",
      "original rows:  (1256, 20)\n",
      "after dups removed:  (1256, 20)\n",
      "[]\n",
      "nba odds data loaded...\n",
      "prop          ast  blk   pa   pr  pra  pts   ra  reb  sb  stl  threes\n",
      "propId count  124  122  125  127  127  129  125  126  10  124     117\n",
      "scraping nhl ...\n",
      "original rows:  (1079, 20)\n",
      "after dups removed:  (1079, 20)\n",
      "['Jani Nyman']\n",
      "nhl odds data loaded...\n",
      "prop          ast  ats  gs  gs1st  gs2plus  gs3plus  gsLast  pts  sog\n",
      "propId count   96  219  11    214      100       41     214   97   87\n"
     ]
    }
   ],
   "source": [
    "print(today, 'run date...\\n')\n",
    "prop_scraper.scrape(\n",
    "    sleep_secs = 3, \n",
    "    specific_props = specified,\n",
    "    leagues_override = prop_scraper.leagues,\n",
    "    an_state_code = 'BC'\n",
    ")\n",
    "\n",
    "prop_scraper.processScrapes(\n",
    "    remove_dups = True,\n",
    "    specific_props = specified\n",
    ")\n",
    "\n",
    "if prop_scraper.scrape_error_flag:\n",
    "    print(prop_scraper.scrape_errors)\n",
    "    #prop_scraper.tryMissingProps()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7abe0c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 run date...\n",
      "\n",
      "bref player pos estimates scraped...\n",
      "missing: [['DEN', 2025], ['SAC', 2025]]\n",
      "bref player pos estimates scraped...\n",
      "bref player pos estimates scraped...\n"
     ]
    }
   ],
   "source": [
    "print(today, 'run date...\\n')\n",
    "#teams = ['GSW','DEN','POR','SAC','TOR','DAL','PHO','CHI','LAL','HOU','MIA','MEM','DET','MIL','NOP','MIN','CLE','OKC','LAC','BRK','SAS','NYK','WAS','CHO','UTA','IND','BOS','PHI','ATL','ORL']\n",
    "scraper.get_bref_pos_estimates(\n",
    "        base_url = 'https://www.basketball-reference.com/teams/{team}/{season}.html#pbp', \n",
    "        today_date = today,\n",
    "        season = season_int,\n",
    "        database_table = 'brefmisc',\n",
    "        team_overrides = None\n",
    ")\n",
    "missing_teams = scraper.scrape_errors['brefmisc']['url']\n",
    "if len(missing_teams):\n",
    "        print('missing:', missing_teams)\n",
    "        for i in missing_teams:\n",
    "                scraper.get_bref_pos_estimates(\n",
    "                        base_url = 'https://www.basketball-reference.com/teams/{team}/{season}.html#pbp', \n",
    "                        today_date = today,\n",
    "                        season = season_int,\n",
    "                        database_table = 'brefmisc',\n",
    "                        team_overrides = [i[0]]\n",
    "                )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8dd73cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 run date...\n",
      "\n",
      "nba team play type scraped...\n",
      "nba team shot zone scraped 10 offensive,  10 defensive loaded...\n",
      "nba team stats scraped...\n",
      "nba team stats scraped...\n",
      "nba player play type scraped...\n",
      "nba player shot zone scraped 112 loaded...\n",
      "nba player passing scraped 112 loaded...\n",
      "nba player rebounding scraped 96 loaded...\n",
      "{'brefmisc': {'url': [], 'db': []}, 'statsteamplaytypes': {'url': [], 'db': []}, 'statsteamshotzones': {'url': [], 'db': []}, 'statsteam': {'url': [], 'db': []}, 'statsteamtotals': {'url': [], 'db': []}, 'statsplayerplaytypes': {'url': [], 'db': []}, 'statsplayershotzones': {'url': [], 'db': []}, 'statsplayerpassing': {'url': [], 'db': []}, 'statsplayerrebounding': {'url': [], 'db': []}}\n"
     ]
    }
   ],
   "source": [
    "print(today, 'run date...\\n')\n",
    "scraper.get_nba_team_playtype_data(\n",
    "    base_url = 'https://www.nba.com/stats/teams/{playtype}?TypeGrouping={sideofball}&SeasonType={type}&Season={season}',\n",
    "    play_types = [\n",
    "        'isolation', 'transition', 'ball-handler', 'roll-man', 'playtype-post-up',\n",
    "        'spot-up', 'hand-off', 'cut', 'off-screen','putbacks'\n",
    "    ],\n",
    "    sides = ['offensive', 'defensive'],\n",
    "    season_type = season_type,  # ['Regular+Season', 'PlayIn', 'Playoffs']\n",
    "    database_table = 'statsteamplaytypes',\n",
    "    season = season_str\n",
    ")\n",
    "\n",
    "scraper.get_nba_team_shotzone_data(\n",
    "    base_url = 'https://www.nba.com/stats/teams/{sideOfBall}?DistanceRange=By+Zone&SeasonType={type}&DateFrom={startDate}&DateTo={endDate}&PerMode={perMode}&Season={season}', \n",
    "    sides = {'offensive':'shooting', 'defensive':'opponent-shooting'},\n",
    "    season_type = season_type,  # ['Regular+Season', 'PlayIn', 'Playoffs']\n",
    "    perMode = per_mode,\n",
    "    database_table = 'statsteamshotzones',\n",
    "    dateRange = dateRange,\n",
    "    season = season_str\n",
    ")\n",
    "# per game\n",
    "scraper.get_nba_team_stats(\n",
    "    base_url = 'https://www.nba.com/stats/teams/{stats}?SeasonType={seasonType}&DateFrom={startDate}&DateTo={endDate}&PerMode={perMode}&Season={season}',\n",
    "    stats = ['traditional', 'advanced', 'opponent'],\n",
    "    season_type = season_type,  # ['Regular+Season', 'PlayIn', 'Playoffs']\n",
    "    perMode = 'PerGame',  # [Totals, PerGame]\n",
    "    database_table = 'statsteam',\n",
    "    dateRange = dateRange,\n",
    "    season = season_str\n",
    ")\n",
    "# totals\n",
    "scraper.get_nba_team_stats(\n",
    "    base_url = 'https://www.nba.com/stats/teams/{stats}?SeasonType={seasonType}&DateFrom={startDate}&DateTo={endDate}&PerMode={perMode}&Season={season}',\n",
    "    stats = ['traditional', 'advanced', 'opponent'],\n",
    "    season_type = season_type,  # ['Regular+Season', 'PlayIn', 'Playoffs']\n",
    "    perMode = per_mode,  # [Totals, PerGame]\n",
    "    database_table = 'statsteamtotals',\n",
    "    dateRange = dateRange,\n",
    "    season = season_str\n",
    ")\n",
    "\n",
    "scraper.get_nba_player_playtype_data(\n",
    "    base_url = 'https://www.nba.com/stats/players/{playtype}?TypeGrouping={sideofball}&SeasonType={type}&Season={season}', \n",
    "    play_types = [\n",
    "        'isolation', 'transition', 'ball-handler', 'roll-man', 'playtype-post-up',\n",
    "        'spot-up', 'hand-off', 'cut', 'off-screen','putbacks'\n",
    "    ],\n",
    "    sides = ['offensive'],\n",
    "    season_type = season_type,  # ['Regular+Season', 'PlayIn', 'Playoffs']\n",
    "    database_table = 'statsplayerplaytypes',\n",
    "    season = season_str\n",
    ")\n",
    "\n",
    "scraper.get_nba_player_shotzone_data(\n",
    "    base_url = 'https://www.nba.com/stats/players/shooting?DistanceRange=By+Zone&SeasonType={type}&DateFrom={startDate}&DateTo={endDate}&PerMode={perMode}&Season={season}',  \n",
    "    season_type = season_type,  # ['Regular+Season', 'PlayIn', 'Playoffs']\n",
    "    perMode = per_mode,\n",
    "    database_table = 'statsplayershotzones',\n",
    "    dateRange = dateRange,\n",
    "    season = season_str\n",
    ")\n",
    "\n",
    "scraper.get_nba_player_passing_data(\n",
    "    base_url = 'https://www.nba.com/stats/players/passing?DateFrom={d1}&DateTo={d2}&PerMode={perMode}&SeasonType={type}&Season={season}', \n",
    "    run_date = run_date,\n",
    "    season_type = season_type,  # ['Regular+Season', 'PlayIn', 'Playoffs']\n",
    "    perMode = per_mode,\n",
    "    database_table = 'statsplayerpassing',\n",
    "    season = season_str\n",
    ")\n",
    "\n",
    "scraper.get_nba_player_rebounding_data(\n",
    "    base_url = 'https://www.nba.com/stats/players/rebounding?DateFrom={d1}&DateTo={d2}&PerMode={perMode}&SeasonType={type}&Season={season}', \n",
    "    run_date = run_date,\n",
    "    season_type = season_type,  # ['Regular+Season', 'PlayIn', 'Playoffs']\n",
    "    perMode = per_mode,\n",
    "    database_table = 'statsplayerrebounding',\n",
    "    season = season_str\n",
    ")\n",
    "\n",
    "if scraper.scrape_error_flag:\n",
    "    print(scraper.scrape_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf58df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prop_scraper.tryMissingProps()\n",
    "# this didn't work as expected, \n",
    "#### added SOG to the nba scrape_errors\n",
    "#### added new key-value pair for the missing prop:  'missing_dates': ['sog', '2025-01-02', 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369da388",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_scraper.scrape_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ab7cd",
   "metadata": {},
   "source": [
    "# loading misscraped passing and rebound date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e94d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nba_api.stats.endpoints import leaguegamefinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "97a922e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cstring = scraper.pymysql_conn_str\n",
    "# qery db to get dates of messed up dates\n",
    "df = pd.read_sql_query(\n",
    "    #sql = \"\"\"SELECT date, COUNT(PLAYER_NAME) n FROM statsplayershotzones GROUP BY date HAVING date > '2024-10-20' and n = 50 ORDER BY date;\"\"\",\n",
    "    sql = \"SELECT DISTINCT date FROM statsteamtotals WHERE date > '2023-10-20' AND date < '2024-07-01';\",\n",
    "    con = cstring\n",
    ")\n",
    "#dates = df[df['n'] == 50]['date'].tolist()\n",
    "dates = df['date'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d4393b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = [pd.to_datetime(i).date() for i in dates]\n",
    "actual = dates_reg_2324 + dates_post_2324\n",
    "np.setdiff1d(actual, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c8e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83d9c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "90bc0bda",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Fetch all games for the current season\n",
    "seasons = '2024-25'\n",
    "gamefinder = leaguegamefinder.LeagueGameFinder(season_nullable=seasons, league_id_nullable='00')\n",
    "games2425 = gamefinder.get_data_frames()[0]\n",
    "games2425.loc[:,'GAME_DATE'] = pd.to_datetime(games2425['GAME_DATE'])\n",
    "games2425 = games2425[games2425['SEASON_ID'].astype(str).str.startswith(('2', '4', '5'))]\n",
    "dates_reg_2425 = games2425[games2425['SEASON_ID'].astype(str).str.startswith(('2'))]['GAME_DATE'].unique().tolist()\n",
    "dates_reg_2425 = [i.date() for i in dates_reg_2425]\n",
    "dates_reg_2425.sort()\n",
    "#dates_post_2425 = games2425[games2425['SEASON_ID'].astype(str).str.startswith(('4', '5'))]['GAME_DATE'].unique().tolist()\n",
    "#dates_post_2425 = [i.date() for i in dates_post_2324]\n",
    "#dates_post_2425.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7817389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HISTORICAL LOADERS\n",
    "####\n",
    "for i in []:\n",
    "    print(i)\n",
    "    d = pd.to_datetime(i)\n",
    "    dateRange = [d, d]\n",
    "    scraper.get_nba_team_shotzone_data(            \n",
    "        base_url = 'https://www.nba.com/stats/teams/{sideOfBall}?DistanceRange=By+Zone&SeasonType={type}&DateFrom={startDate}&DateTo={endDate}&PerMode={perMode}&Season={season}', \n",
    "        sides = {'offensive':'shooting', 'defensive':'opponent-shooting'},\n",
    "        season_type = 'Regular+Season',  # ['Regular+Season', 'PlayIn', 'Playoffs']\n",
    "        perMode = 'Totals', #[Totals, PerMode]\n",
    "        database_table = 'statsteamshotzones',\n",
    "        dateRange = dateRange,\n",
    "        season = '2023-24'\n",
    "    )\n",
    "\n",
    "\n",
    "for i in []:\n",
    "    print(i)\n",
    "    d = pd.to_datetime(i)\n",
    "    dateRange = [d, d]\n",
    "    scraper.get_nba_player_shotzone_data(\n",
    "        #base_url = 'https://www.nba.com/stats/players/shooting?DistanceRange=By+Zone&LastNGames={lastNgames}&SeasonType={type}&DateTo={endDate}', \n",
    "        base_url = 'https://www.nba.com/stats/players/shooting?DistanceRange=By+Zone&SeasonType={type}&DateFrom={startDate}&DateTo={endDate}&PerMode=Totals&Season=2023-24',  \n",
    "        season_type = 'PlayIn',  # ['Regular+Season', 'PlayIn', 'Playoffs']\n",
    "        lastNgames = 0,\n",
    "        database_table = 'statsplayershotzones',\n",
    "        dateRange = dateRange\n",
    "    )\n",
    "\n",
    "\n",
    "for i in []:\n",
    "    print(i)\n",
    "    d = pd.to_datetime(i)\n",
    "    scraper.get_nba_player_passing_data(\n",
    "        base_url = 'https://www.nba.com/stats/players/passing?DateFrom={d1}&DateTo={d2}&PerMode=Totals&SeasonType={type}&Season=2023-24', \n",
    "        run_date = d,\n",
    "        season_type = 'Playoffs',  # ['Regular+Season', 'PlayIn', 'Playoffs']\n",
    "        database_table = 'statsplayerpassing'\n",
    "    )\n",
    "\n",
    "#\n",
    "for i in []:\n",
    "    print(i)\n",
    "    d = pd.to_datetime(i)\n",
    "    scraper.get_nba_player_rebounding_data(\n",
    "        base_url = 'https://www.nba.com/stats/players/rebounding?DateFrom={d1}&DateTo={d2}&PerMode=Totals&SeasonType={type}&Season=2023-24', \n",
    "        run_date = d,\n",
    "        season_type = 'Playoffs',  # ['Regular+Season', 'PlayIn', 'Playoffs']\n",
    "        database_table = 'statsplayerrebounding'\n",
    "    )\n",
    "\n",
    "p = 'Regular+Season'\n",
    "for i in dates_reg_2425:\n",
    "    print(i)\n",
    "    d = pd.to_datetime(i)\n",
    "    dateRange = [d, d]  \n",
    "    # per game\n",
    "    scraper.get_nba_team_stats(\n",
    "        base_url = 'https://www.nba.com/stats/teams/{stats}?SeasonType={seasonType}&DateFrom={startDate}&DateTo={endDate}&PerMode={perMode}&Season={season}',\n",
    "        stats = ['traditional', 'advanced', 'opponent'],\n",
    "        season_type = p,  # ['Regular+Season', 'PlayIn', 'Playoffs']\n",
    "        perMode = 'PerGame',  # [Totals, PerGame]\n",
    "        database_table = 'statsteam',\n",
    "        dateRange = dateRange,\n",
    "        season = '2024-25'\n",
    "    )\n",
    "    # totals\n",
    "    scraper.get_nba_team_stats(\n",
    "        base_url = 'https://www.nba.com/stats/teams/{stats}?SeasonType={seasonType}&DateFrom={startDate}&DateTo={endDate}&PerMode={perMode}&Season={season}',\n",
    "        stats = ['traditional', 'advanced', 'opponent'],\n",
    "        season_type = p,  # ['Regular+Season', 'PlayIn', 'Playoffs']\n",
    "        perMode = 'Totals',  # [Totals, PerGame]\n",
    "        database_table = 'statsteamtotals',\n",
    "        dateRange = dateRange,\n",
    "        season = '2024-25'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512dde7f",
   "metadata": {},
   "source": [
    "# scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67c6be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40b361e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service('..\\\\..\\\\browser\\\\geckodriver.exe')\n",
    "driver = webdriver.Firefox(service=service)\n",
    "url = 'https://www.nba.com/stats/players/rebounding?DateFrom=10%2F24%2F2024&DateTo=10%2F24%2F2024'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b6c136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f090ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "26d8b9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jrbrz\\AppData\\Local\\Temp\\ipykernel_17592\\2715966764.py:58: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(table_html)[0]  # Convert to DataFrame\n",
      "C:\\Users\\jrbrz\\AppData\\Local\\Temp\\ipykernel_17592\\2715966764.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_team_data = pd.concat([all_team_data, df])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error DEN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jrbrz\\AppData\\Local\\Temp\\ipykernel_17592\\2715966764.py:58: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(table_html)[0]  # Convert to DataFrame\n",
      "C:\\Users\\jrbrz\\AppData\\Local\\Temp\\ipykernel_17592\\2715966764.py:58: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(table_html)[0]  # Convert to DataFrame\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error TORDAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jrbrz\\AppData\\Local\\Temp\\ipykernel_17592\\2715966764.py:58: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(table_html)[0]  # Convert to DataFrame\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error CHI\n",
      "error LAL\n",
      "error HOU\n",
      "error MIA\n",
      "error MEM\n",
      "error DET\n",
      "error MIL\n",
      "error NOP\n",
      "error MIN\n",
      "error CLE\n",
      "error OKC\n",
      "error LAC\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# loop through each team webpage to gather data        \u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m bref_team_abbr:\n\u001b[1;32m---> 33\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m         url \u001b[38;5;241m=\u001b[39m base_url\u001b[38;5;241m.\u001b[39mformat(team \u001b[38;5;241m=\u001b[39m i, season \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(season))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "service = Service('..\\\\..\\\\browser\\\\geckodriver.exe')\n",
    "driver = webdriver.Firefox(service=service)\n",
    "# loop through each team webpage to gather data        \n",
    "base_url = 'https://www.basketball-reference.com/teams/{team}/{season}.html#pbp'\n",
    "\n",
    "season = 2025\n",
    "\n",
    "#all_team_data = []\n",
    "url_errors = []\n",
    "\n",
    "# basketball ref team url abbrevs\n",
    "bref_team_abbr = [\n",
    "    'GSW','DEN','POR', 'SAC','TOR',\n",
    "    'DAL','PHO','CHI','LAL','HOU',\n",
    "    'MIA','MEM','DET','MIL','NOP','MIN',\n",
    "    'CLE','OKC','LAC','BRK','SAS','NYK','WAS','CHO',\n",
    "    'UTA','IND','BOS','PHI','ATL','ORL'\n",
    "]\n",
    "\n",
    "# col names in the database\n",
    "bref_cols = [\n",
    "    'player', 'age', 'pos', 'gp', 'gs', 'mp', 'PG', 'SG', 'SF',\n",
    "    'PF', 'C', 'onCourtPlusMinusPer100', 'onOffPlusMinusPer100',\n",
    "    'badPass', 'lostBall', 'shootFoulCommitted', 'offFoulCommitted',\n",
    "    'shootFoulDrawn', 'offFoulDrawn', 'ptsGenFromAst', 'andOnes', 'shotsBlk', 'awards',\n",
    "    'date', 'team'\n",
    "]\n",
    "\n",
    "all_team_data = pd.DataFrame(columns=bref_cols)\n",
    "\n",
    "# loop through each team webpage to gather data        \n",
    "for i in bref_team_abbr:\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        url = base_url.format(team = i, season = str(season))\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        #try:\n",
    "        #    popup = driver.find_element(By.ID, 'modal-close')\n",
    "            # Wait for the popup to be present and visible\n",
    "            #popup = WebDriverWait(driver, 3).until(\n",
    "            #    EC.visibility_of_element_located(By.ID, 'modal-close')\n",
    "            #)\n",
    "        #    popup.click()\n",
    "        #except: continue\n",
    "\n",
    "        table_id = 'pbp_stats'\n",
    "        table = None  # Placeholder for the table element\n",
    "        scroll_attempts = 30  # Number of scrolling attempts\n",
    "        scroll_step = 500  # Pixels to scroll down on each attempt\n",
    "  \n",
    "        # this was removed out of the loop below. loop stopped working and selenium is now able to find it without scrolling\n",
    "        table = driver.find_element(By.ID, table_id)\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", table)\n",
    "\n",
    "        table_html = table.get_attribute('outerHTML')  # Get table HTML\n",
    "        df = pd.read_html(table_html)[0]  # Convert to DataFrame\n",
    "        df = df.iloc[:,1:].reset_index(drop=True)\n",
    "        df.loc[:,'date'] = '2025'\n",
    "        df.loc[:,'team'] = i\n",
    "        df.columns = bref_cols\n",
    "\n",
    "        all_team_data = pd.concat([all_team_data, df])\n",
    "    \n",
    "    except:\n",
    "        print('error', i)\n",
    "        continue\n",
    "    \n",
    "\n",
    "driver.close()\n",
    "#bref_pos_estimates = pd.DataFrame(all_team_data, columns = bref_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "93d5d2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSW\n",
      "DEN\n",
      "POR\n",
      "SAC\n",
      "PHO\n",
      "CHI\n",
      "LAL\n",
      "HOU\n",
      "MIA\n",
      "MEM\n",
      "DET\n",
      "NOP\n",
      "MIN\n",
      "CLE\n",
      "OKC\n",
      "LAC\n",
      "BRK\n",
      "SAS\n",
      "NYK\n",
      "CHO\n",
      "UTA\n",
      "IND\n",
      "BOS\n",
      "PHI\n",
      "ATL\n",
      "ORL\n"
     ]
    }
   ],
   "source": [
    "for i in all_team_data.team.unique():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27c63f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b67bbf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "popup = driver.find_element(By.ID, 'modal-close')\n",
    "popup.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c974bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was removed out of the loop below. loop stopped working and selenium is now able to find it without scrolling\n",
    "table = driver.find_element(By.ID, table_id)\n",
    "\n",
    "driver.execute_script(\"arguments[0].scrollIntoView();\", table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bbd8738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jrbrz\\AppData\\Local\\Temp\\ipykernel_17592\\4285168731.py:2: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(table_html)[0]  # Convert to DataFrame\n"
     ]
    }
   ],
   "source": [
    "table_html = table.get_attribute('outerHTML')  # Get table HTML\n",
    "df = pd.read_html(table_html)[0]  # Convert to DataFrame\n",
    "df = df.iloc[:,1:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b519dab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"640c6a3f-f302-445d-a3ed-fa522d4d8c12\", element=\"bea42cb3-e84f-4cba-b374-3502da78fdf0\")>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9077aee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "propfarm-_NXI0yZr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
