{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "286006d1-0b26-4543-ad24-81c23f793f5e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### scraping prop lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c727ece0-5aef-4894-bc86-ebf395544eab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# initial run(0) or update run (1)\n",
    "update = 0\n",
    "# https://www.rotowire.com/betting/mlb/player-props.php\n",
    "# if you don't want to restart kernal, dump any existing data\n",
    "try:\n",
    "    del data\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import requests, time, re, os, json\n",
    "#import mysql.connector\n",
    "#import mysql, pymysql, pyodbc\n",
    "#import sqlalchemy as sal\n",
    "#from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np\n",
    "#from bs4 import BeautifulSoup as bs\n",
    "from datetime import date\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "#importing credentials from txt file\n",
    "with open('../../../Notes-General/config.txt', 'r') as f:\n",
    "    creds = f.read()\n",
    "creds = json.loads(creds)\n",
    "\n",
    "# path to downloads folder\n",
    "download_path = creds['downloads']\n",
    "\n",
    "#sportsdataio MLB API\n",
    "mlbKey = creds['sportsdataiomlbAPI']\n",
    "\n",
    "#### using the save as button on the page to save the files individually.\n",
    "#### the rows of the tables that are not visible are hidden from HTML\n",
    "#### saving is the only way to get all the rows that I know at this time\n",
    "\n",
    "# path to webdriver for selenium\n",
    "try:\n",
    "    service = Service(r\"..\\browser\\geckodriver.exe\")\n",
    "    driver = webdriver.Firefox(service=service)\n",
    "    waitTime = 10\n",
    "\n",
    "    site = \"https://www.rotowire.com/betting/mlb/player-props.php\"\n",
    "    driver.get(site)\n",
    "except:\n",
    "    driver.close()\n",
    "\n",
    "data_prop_names = [\"moneyline-props\",\"props-strikeouts\",\"props-er\",\n",
    "                   \"props-bases\",\"props-runs\"]\n",
    "missing = []\n",
    "for i in range(len(data_prop_names)):\n",
    "# find the element in the source\n",
    "    try:\n",
    "        ele = driver.find_element(By.CSS_SELECTOR, \"div[id={}]\".format(data_prop_names[i]))\n",
    "        # retrieve its page coords\n",
    "        loc = ele.location\n",
    "        #scroll to the location to activate the table creation\n",
    "        driver.execute_script(\"window.scrollTo(0, {});\".format(str(loc[\"y\"])))\n",
    "        # pause for data loading\n",
    "        time.sleep(3)\n",
    "        ###### save to csv \n",
    "        export_button = ele.find_element(By.CLASS_NAME, \"is-csv\")\n",
    "        export_button.click()\n",
    "    except Exception as e:\n",
    "        print(data_prop_names[i], e)\n",
    "        missing.append(i)\n",
    "        continue\n",
    "\n",
    "driver.close()\n",
    "\n",
    "# columns to use for renaming csv's\n",
    "columns = ['PLAYER', 'team', 'opp', 'dk_line', 'dk_oOdds', 'dk_uOdds',\n",
    "          'fd_line', 'fd_oOdds', 'fd_uOdds','m_line', 'm_oOdds', 'm_uOdds',\n",
    "          'pb_line', 'pb_oOdds', 'pb_uOdds']\n",
    "# prop names to store\n",
    "db_names = [\"moneyline-props\",\"K\",\"ER\",\"TB\",\"R\"]\n",
    "\n",
    "# will be used to get the correct file number when there are missing files\n",
    "count = 0\n",
    "# loop through each file to agg into a single data frame\n",
    "for i in range(0, len(data_prop_names)):\n",
    "    #uses the indices for the missing odds files\n",
    "    if i in missing:\n",
    "        continue\n",
    "    else:\n",
    "        stat = data_prop_names[i]\n",
    "        if i == 0:\n",
    "            path = download_path + \"mlb-player-props-rotowire.csv\"\n",
    "            raw_data = pd.read_csv(path, skiprows=1)\n",
    "            \n",
    "            batter_props = [\"H\", \"Hx2\", \"HR\", \"RBI\", \"SB\"]\n",
    "            \n",
    "            df_hit = raw_data.iloc[:,[0,1,2, 3,4,5,6]]\n",
    "            df_hit.columns = ['PLAYER', 'team', 'opp',\n",
    "                              'dk_oOdds', 'fd_oOdds', 'm_oOdds', 'pb_oOdds']\n",
    "            df_hit.loc[:,['dk_line', 'fd_line','m_line','pb_line']] = 0.5\n",
    "            df_hit.loc[:,['dk_uOdds', 'fd_uOdds','m_uOdds', 'pb_uOdds']] = np.nan\n",
    "            df_hit.loc[:,['stat']] = \"H\"\n",
    "            \n",
    "            df_twoHit = raw_data.iloc[:,[0,1,2, 7,8,9,10]]\n",
    "            df_twoHit.columns = ['PLAYER', 'team', 'opp',\n",
    "                              'dk_oOdds', 'fd_oOdds', 'm_oOdds', 'pb_oOdds']\n",
    "            df_twoHit.loc[:,['dk_line', 'fd_line','m_line','pb_line']] = 1.5\n",
    "            df_twoHit.loc[:,['dk_uOdds', 'fd_uOdds','m_uOdds', 'pb_uOdds']] = np.nan\n",
    "            df_twoHit.loc[:,['stat']] = \"Hx2\"\n",
    "            \n",
    "            df_hr = raw_data.iloc[:,[0,1,2, 11,12,13,14]]\n",
    "            df_hr.columns = ['PLAYER', 'team', 'opp',\n",
    "                              'dk_oOdds', 'fd_oOdds', 'm_oOdds', 'pb_oOdds']\n",
    "            df_hr.loc[:,['dk_line', 'fd_line','m_line','pb_line']] = 0.5\n",
    "            df_hr.loc[:,['dk_uOdds', 'fd_uOdds','m_uOdds', 'pb_uOdds']] = np.nan\n",
    "            df_hr.loc[:,['stat']] = \"HR\"\n",
    "            \n",
    "            df_rbi = raw_data.iloc[:,[0,1,2, 15,16,17,18]]\n",
    "            df_rbi.columns = ['PLAYER', 'team', 'opp',\n",
    "                              'dk_oOdds', 'fd_oOdds', 'm_oOdds', 'pb_oOdds']\n",
    "            df_rbi.loc[:,['dk_line', 'fd_line','m_line','pb_line']] = 0.5\n",
    "            df_rbi.loc[:,['dk_uOdds', 'fd_uOdds','m_uOdds', 'pb_uOdds']] = np.nan\n",
    "            df_rbi.loc[:,['stat']] = \"RBI\"\n",
    "            \n",
    "            df_sb = raw_data.iloc[:,[0,1,2, 19,20,21,22]]\n",
    "            df_sb.columns = ['PLAYER', 'team', 'opp',\n",
    "                              'dk_oOdds', 'fd_oOdds', 'm_oOdds', 'pb_oOdds']\n",
    "            df_sb.loc[:,['dk_line', 'fd_line','m_line','pb_line']] = 0.5\n",
    "            df_sb.loc[:,['dk_uOdds', 'fd_uOdds','m_uOdds', 'pb_uOdds']] = np.nan\n",
    "            df_sb.loc[:,['stat']] = \"SB\"\n",
    "            \n",
    "            data = pd.concat([df_hit, df_twoHit, df_hr, df_rbi, df_sb])\n",
    "\n",
    "               \n",
    "        elif 0 in missing:\n",
    "            path = download_path + \"mlb-player-props-rotowire.csv\"\n",
    "            data = pd.read_csv(path, skiprows=1)\n",
    "            data.columns=columns\n",
    "            data['stat'] = db_names[i]\n",
    "        else:\n",
    "            count += 1\n",
    "            path = download_path + \"mlb-player-props-rotowire({}).csv\".format(count)\n",
    "            temp = pd.read_csv(path, skiprows=1)\n",
    "            temp.columns=columns\n",
    "            temp['stat'] = db_names[i]\n",
    "            # concat data into main df    \n",
    "            data = pd.concat([data, temp])\n",
    "        #delete file after use\n",
    "        os.remove(path)\n",
    "# using dk line as the default and using the min of the other options when DK is not available\n",
    "data[\"line\"] = np.where(data[\"dk_line\"].isna(), \n",
    "                       data[[\"fd_line\",\"m_line\",\"pb_line\"]].min(axis=1, skipna=True),\n",
    "                       data[\"dk_line\"])\n",
    "data[\"oOdds\"] = np.where(data[\"dk_oOdds\"].isna(), \n",
    "                       data[[\"fd_oOdds\",\"m_oOdds\",\"pb_oOdds\"]].max(axis=1, skipna=True),\n",
    "                       data[\"dk_oOdds\"])\n",
    "data[\"uOdds\"] = np.where(data[\"dk_uOdds\"].isna(), \n",
    "                       data[[\"fd_uOdds\",\"m_uOdds\",\"pb_uOdds\"]].max(axis=1, skipna=True),\n",
    "                       data[\"dk_uOdds\"])\n",
    "\n",
    "data = data[[\"PLAYER\", \"team\", \"stat\", \"line\", \"oOdds\", \"uOdds\"]]\n",
    "data = data.dropna(subset=['oOdds'])\n",
    "# adding the date of the odds\n",
    "data.loc[:,'date'] = date.today()  \n",
    "\n",
    "date_string = str(date.today())\n",
    "# if this is not an update run then the data will be saved. If it is an updated (1) then\n",
    "# the next cell will need to be executed to filter\n",
    "if update == 0:\n",
    "    data.to_csv(\"../data/{}_MLBodds.csv\".format(date_string), index=False)\n",
    "else:\n",
    "    # updating previously pulled odds\n",
    "    # if teams have completed or started their games they need to be filtered \n",
    "    # from the newest pull bec the roto site does not accurately save lines once the game start\n",
    "\n",
    "    # user input to \n",
    "    filter_teams = input(\"Enter Teams Abbrev to filter separated by space >>\").split()\n",
    "\n",
    "    #filtering the input teams from the updated odds data\n",
    "    data = data[~data['team'].isin(filter_teams)]\n",
    "    # setting player as index temporarily \n",
    "    data.set_index(\"PLAYER\", inplace=True)\n",
    "\n",
    "    # import the prior odds data saved\n",
    "    prevOddsData = pd.read_csv(\"../data/{}_MLBodds.csv\".format(date_string), index_col=\"PLAYER\")\n",
    "\n",
    "    # keep players data in the old data when they aren't present in the new data and then add\n",
    "    # all of the new data (this achieves the update portion\n",
    "    data = pd.concat([data[~data.index.isin(prevOddsData.index)], prevOddsData]).reset_index()\n",
    "\n",
    "    data.to_csv(\"../data/{}_MLBodds.csv\".format(date_string), index=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ef0eddc-13e7-4927-a8e8-09a46cf92960",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pybaseball' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpybaseball\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m statcast\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsapi\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mpybaseball\u001b[49m\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39menable()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pybaseball' is not defined"
     ]
    }
   ],
   "source": [
    "## import pybaseball\n",
    "from pybaseball import statcast\n",
    "import statsapi\n",
    "pybaseball.cache.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27984b1-fa7c-427f-88e6-46a0780c68e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac5af4c-3f96-4af2-a50b-329907cc3bb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# py baseball\n",
    "data = statcast(start_dt=\"2023-03-15\", end_dt=\"2023-04-28\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb5cc0-2a07-4362-9374-5ae635d77011",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfe89a5-5872-4ec9-8c9c-d99a5816e2e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['events'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a357cdd-6640-452c-931f-669066bc92f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3961eaa-081b-465c-aaef-22b359b938c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "0172e2b6-2149-4dde-a209-f74b84844468",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4 calls\n",
    "d = \"2023-MAY-05\"\n",
    "\n",
    "games_by_date = \"https://api.sportsdata.io/v3/mlb/scores/json/GamesByDate/{date}?key={key}\".format(date= d, key=mlbKey)\n",
    "\n",
    "games  = requests.get(games_by_date)\n",
    "\n",
    "games_on_a_date = []\n",
    "\n",
    "for j in games.json():\n",
    "    games_on_a_date.append(j['GameID'])\n",
    "\n",
    "print(len(games_on_a_date))\n",
    "\n",
    "gid = games_on_a_date[0]\n",
    "\n",
    "props_for_single_game = \"https://api.sportsdata.io/v3/mlb/odds/json/BettingPlayerPropsByGameID/{gameId}?key={key}\".format(gameId= str(gid), key=mlbKey)\n",
    "props = requests.get(props_for_single_game)\n",
    "\n",
    "props.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ced716f-03f1-4619-8df1-2b0b591b434c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
