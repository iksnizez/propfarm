{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d14d6c-839b-45c5-9954-95abfabc13ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial run(0) or update run (1)\n",
    "update = 0\n",
    "# https://www.rotowire.com/betting/nba/player-props.php\n",
    "\n",
    "import requests, time, re, os, json, mysql.connector\n",
    "#import mysql, pymysql, pyodbc\n",
    "#import sqlalchemy as sal\n",
    "#from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np\n",
    "#from bs4 import BeautifulSoup as bs\n",
    "from datetime import date\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "#importing credentials from txt file\n",
    "with open('../../../Notes-General/config.txt', 'r') as f:\n",
    "    creds = f.read()\n",
    "creds = json.loads(creds)\n",
    "\n",
    "# path to downloads folder\n",
    "download_path = creds['downloads']\n",
    "\n",
    "#### using the save as button on the page to save the files individually.\n",
    "#### the rows of the tables that are not visible are hidden from HTML\n",
    "#### saving is the only way to get all the rows that I know at this time\n",
    "\n",
    "# path to webdriver for selenium\n",
    "try:\n",
    "    service = Service(r\"..\\browser\\geckodriver.exe\")\n",
    "    driver = webdriver.Firefox(service=service)\n",
    "    waitTime = 10\n",
    "\n",
    "    site = \"https://www.rotowire.com/betting/nba/player-props.php\"\n",
    "    driver.get(site)\n",
    "except:\n",
    "    driver.close()\n",
    "\n",
    "# will be used to loop through the webpage\n",
    "data_prop_names = [\"PTS\",\"REB\",\"AST\",\n",
    "                   \"THREES\",\"BLK\",\"STL\",\n",
    "                   \"TURNOVERS\",\"PTSREBAST\",\"PTSREB\",\n",
    "                   \"PTSAST\",\"REBAST\",\"STLBLK\"]\n",
    "missing = []\n",
    "for i in range(len(data_prop_names)):\n",
    "# find the element in the source\n",
    "    try:\n",
    "        ele = driver.find_element(By.CSS_SELECTOR, \"div[data-prop={}]\".format(data_prop_names[i]))\n",
    "        # retrieve its page coords\n",
    "        loc = ele.location\n",
    "        #scroll to the location to activate the table creation\n",
    "        driver.execute_script(\"window.scrollTo(0, {});\".format(str(loc[\"y\"])))\n",
    "        # pause for data loading\n",
    "        time.sleep(3)\n",
    "        ###### save to csv \n",
    "        export_button = ele.find_element(By.CLASS_NAME, \"is-csv\")\n",
    "        export_button.click()\n",
    "    except Exception as e:\n",
    "        print(data_prop_names[i], e)\n",
    "        missing.append(i)\n",
    "        continue\n",
    "    \n",
    "driver.close()\n",
    "\n",
    "# columns to use for renaming csv's\n",
    "columns = ['PLAYER', 'team', 'opp', 'dk_line', 'dk_oOdds', 'dk_uOdds',\n",
    "          'fd_line', 'fd_oOdds', 'fd_uOdds','m_line', 'm_oOdds', 'm_uOdds',\n",
    "          'pb_line', 'pb_oOdds', 'pb_uOdds']\n",
    "# will be used to get the correct file number when there are missing files\n",
    "count = 0\n",
    "# loop through each file to agg into a single data frame\n",
    "for i in range(0, len(data_prop_names)):\n",
    "    #uses the indices for the missing odds files\n",
    "    if i in missing:\n",
    "        continue\n",
    "    else:\n",
    "        stat = data_prop_names[i]\n",
    "        if i == 0:\n",
    "            path = download_path + \"nba-player-props-rotowire.csv\"\n",
    "            data = pd.read_csv(path, skiprows=1)\n",
    "            data.columns=columns\n",
    "            data['stat'] = stat\n",
    "        else:\n",
    "            count += 1\n",
    "            path = download_path + \"nba-player-props-rotowire({}).csv\".format(count)\n",
    "            temp = pd.read_csv(path, skiprows=1)\n",
    "            temp.columns=columns\n",
    "            temp['stat'] = stat\n",
    "            # concat data into main df    \n",
    "            data = pd.concat([data, temp])\n",
    "        #delete file after use\n",
    "        os.remove(path)\n",
    "# using dk line as the default and averaging the other options when DK is not available\n",
    "data[\"line\"] = np.where(data[\"dk_line\"].isna(), \n",
    "                       data[[\"fd_line\",\"m_line\",\"pb_line\"]].mean(axis=1, skipna=True),\n",
    "                       data[\"dk_line\"])\n",
    "data[\"oOdds\"] = np.where(data[\"dk_oOdds\"].isna(), \n",
    "                       data[[\"fd_oOdds\",\"m_oOdds\",\"pb_oOdds\"]].mean(axis=1, skipna=True),\n",
    "                       data[\"dk_oOdds\"])\n",
    "data[\"uOdds\"] = np.where(data[\"dk_uOdds\"].isna(), \n",
    "                       data[[\"fd_uOdds\",\"m_uOdds\",\"pb_uOdds\"]].mean(axis=1, skipna=True),\n",
    "                       data[\"dk_uOdds\"])\n",
    "\n",
    "data = data[[\"PLAYER\", \"team\", \"stat\", \"line\", \"oOdds\", \"uOdds\"]]\n",
    "# adding the date of the odds\n",
    "data.loc[:,'date'] = date.today()  \n",
    "\n",
    "date_string = str(date.today())\n",
    "# if this is not an update run then the data will be saved. If it is an updated (1) then\n",
    "# the next cell will need to be executed to filter\n",
    "if update == 0:\n",
    "    data.to_csv(\"../data/{}_odds.csv\".format(date_string), index=False)\n",
    "else:\n",
    "    # updating previously pulled odds\n",
    "    # if teams have completed or started their games they need to be filtered \n",
    "    # from the newest pull bec the roto site does not accurately save lines once the game start\n",
    "\n",
    "    # user input to \n",
    "    filter_teams = input(\"Enter Teams Abbrev to filter separated by space >>\").split()\n",
    "\n",
    "    #filtering the input teams from the updated odds data\n",
    "    data = data[~data['team'].isin(filter_teams)]\n",
    "    # setting player as index temporarily \n",
    "    data.set_index(\"PLAYER\", inplace=True)\n",
    "\n",
    "    # import the prior odds data saved\n",
    "    prevOddsData = pd.read_csv(\"../data/{}_odds.csv\".format(date_string), index_col=\"PLAYER\")\n",
    "\n",
    "    # keep players data in the old data when they aren't present in the new data and then add\n",
    "    # all of the new data (this achieves the update portion\n",
    "    data = pd.concat([data[~data.index.isin(prevOddsData.index)], prevOddsData]).reset_index()\n",
    "\n",
    "    data.to_csv(\"../data/{}_odds.csv\".format(date_string), index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30bffed3-9032-4cf3-8452-1b5d92037fd5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### this facilitates programmatically accessing each prop table data\n",
    "### but only grabs the players visible on initial load. I don't know\n",
    "### how to scroll the div within the page yet.\n",
    "\n",
    "try:\n",
    "    # path to webdriver for selenium\n",
    "    service = Service(r\"..\\browser\\geckodriver.exe\")\n",
    "\n",
    "    driver = webdriver.Firefox(service=service)\n",
    "    waitTime = 10\n",
    "\n",
    "    site = \"https://www.rotowire.com/betting/nba/player-props.php\"\n",
    "    driver.get(site)\n",
    "\n",
    "\n",
    "    # will be used to loop through the webpage\n",
    "    data_prop_names = [\"PTS\",\"REB\",\"AST\",\"THREES\",\"BLK\",\"STL\",\"TURNOVERS\",\"PTSREBAST\",\"PTSREB\",\"PTSAST\",\"REBAST\",\"STLBLK\"]\n",
    "    for i in data_prop_names:\n",
    "    # find the element in the source\n",
    "        print(i)\n",
    "        ele = driver.find_element(By.CSS_SELECTOR, \"div[data-prop={}]\".format(i))\n",
    "        # retrieve its page coords\n",
    "        loc = ele.location\n",
    "        #scroll to the location to activate the table creation\n",
    "        driver.execute_script(\"window.scrollTo(0, {});\".format(str(loc[\"y\"])))\n",
    "        # pause for data loading\n",
    "        time.sleep(1)\n",
    "\n",
    "        #re-search for the element to get the data with the table populated\n",
    "        ele = driver.find_element(By.CSS_SELECTOR, \"div[data-prop={}]\".format(i))\n",
    "\n",
    "        names = ele.find_element(By.CLASS_NAME, \"webix_ss_left\")\n",
    "        remaining_data = ele.find_element(By.CLASS_NAME, \"webix_ss_center\")\n",
    "\n",
    "        ##### names #####\n",
    "        n = names.find_elements(By.CLASS_NAME, \"webix_cell  \")\n",
    "        PLAYER = []\n",
    "        stat = []\n",
    "        for j in n:\n",
    "            name = \" \".join(j.text.split()).strip()\n",
    "            PLAYER.append(name)\n",
    "            stat.append(i.lower())\n",
    "            #row = i.get_attribute('aria-rowindex')\n",
    "            #col = i.get_attribute('aria-colindex')\n",
    "\n",
    "        # pulling team and book line/odds data\n",
    "        cols = remaining_data.find_elements(By.CLASS_NAME, \"webix_column \")\n",
    "\n",
    "        ##### teams #####\n",
    "        teams = cols[0].find_elements(By.CLASS_NAME, \"webix_cell  \")\n",
    "        team = []\n",
    "        for t in teams:\n",
    "            team.append(t.text)\n",
    "\n",
    "        # this holds the location of each data point in remaining_data\n",
    "        # loc is the index and data will hold the actual line values\n",
    "        books = {\n",
    "            2:{\"data\":[]}, 3:{\"data\":[]}, 4:{\"data\":[]},\n",
    "            5:{\"data\":[]}, 6:{\"data\":[]}, 7:{\"data\":[]},\n",
    "            8:{\"data\":[]}, 9:{\"data\":[]}, 10:{\"data\":[]},\n",
    "            11:{\"data\":[]}, 12:{\"data\":[]}, 13:{\"data\":[]}\n",
    "        }\n",
    "\n",
    "        for j in books.keys():\n",
    "            #HTML hides HTML source data if it is not all visible on screen, pointsBET uOdds are offscreen\n",
    "            #I can't figure out FIrefox zoom with Selenium so I am skipping Pointsbet for this grouping\n",
    "            try:\n",
    "                temp_data = cols[j].find_elements(By.CLASS_NAME, \"webix_cell  \")\n",
    "                for h in temp_data:\n",
    "                    try:\n",
    "                        books[j]['data'].append(float(h.text))\n",
    "                    except:\n",
    "                        books[j]['data'].append(np.nan)\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        #using  PTS to start the main dataframe since each table is not sorted the same way\n",
    "        if i == \"PTS\":\n",
    "            # create main dataframe that will receive all the other data points\n",
    "            data = pd.DataFrame(list(zip(PLAYER, team, stat, \n",
    "                                 books[2]['data'], books[3]['data'], books[4]['data'], \n",
    "                                 books[5]['data'], books[6]['data'], books[7]['data'],\n",
    "                                 books[8]['data'], books[9]['data'], books[10]['data'],\n",
    "                                 books[11]['data'], books[12]['data'], books[13]['data'])),\n",
    "                        columns=[\"PLAYER\", \"team\", \"stat\", \n",
    "                          \"dk_line\", \"dk_oOdds\", \"dk_uOdds\",\n",
    "                          \"fd_line\", \"fd_oOdds\", \"fd_uOdds\",\n",
    "                          \"m_line\", \"m_oOdds\", \"m_uOdds\",\n",
    "                          \"pb_line\", \"pb_oOdds\", \"pb_uOdds\"])\n",
    "\n",
    "        else:\n",
    "            # combine all the data for the other stat lines into the main one\n",
    "            temp = pd.DataFrame(list(zip(PLAYER, team, stat, \n",
    "                                 books[2]['data'], books[3]['data'], books[4]['data'], \n",
    "                                 books[5]['data'], books[6]['data'], books[7]['data'],\n",
    "                                 books[8]['data'], books[9]['data'], books[10]['data'],\n",
    "                                 books[11]['data'], books[12]['data'], books[13]['data'])),\n",
    "                                columns=[\"PLAYER\", \"team\", \"stat\", \n",
    "                                  \"dk_line\", \"dk_oOdds\", \"dk_uOdds\",\n",
    "                                  \"fd_line\", \"fd_oOdds\", \"fd_uOdds\",\n",
    "                                  \"m_line\", \"m_oOdds\", \"m_uOdds\",\n",
    "                                  \"pb_line\", \"pb_oOdds\", \"pb_uOdds\"])\n",
    "            \n",
    "            data = pd.concat([data, temp])\n",
    "\n",
    "    # using dk line as the default and averaging the other options when DK is not available\n",
    "    data[\"line\"] = np.where(data[\"dk_line\"].isna(), \n",
    "                           data[[\"fd_line\",\"m_line\",\"pb_line\"]].mean(axis=1, skipna=True),\n",
    "                           data[\"dk_line\"])\n",
    "    data[\"oOdds\"] = np.where(data[\"dk_oOdds\"].isna(), \n",
    "                           data[[\"fd_oOdds\",\"m_oOdds\",\"pb_oOdds\"]].mean(axis=1, skipna=True),\n",
    "                           data[\"dk_oOdds\"])\n",
    "    data[\"uOdds\"] = np.where(data[\"dk_uOdds\"].isna(), \n",
    "                           data[[\"fd_uOdds\",\"m_uOdds\",\"pb_uOdds\"]].mean(axis=1, skipna=True),\n",
    "                           data[\"dk_uOdds\"])\n",
    "\n",
    "    data = data[[\"PLAYER\", \"team\", \"stat\", \"line\", \"oOdds\", \"uOdds\"]]\n",
    "    # adding the date of the odds\n",
    "    data.loc[:,'date'] = date.today()  \n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    # flattening all the stat lines for each player into a single line instead of multiple entries for each player\n",
    "    data = data.pivot(index=[\"PLAYER\", \"team\", \"date\"],\n",
    "                columns=[\"stat\"],\n",
    "                values=[\"line\", \"oOdds\",\"uOdds\"]\n",
    "    ).reset_index()\n",
    "    # combining the multi-column index names into a single name\n",
    "    data.columns   = ['_'.join(col) for col in data.columns.values]\n",
    "    \n",
    "    date_string = str(date.today())\n",
    "    data.to_csv(\"../output/{}_odds.csv\".format(date_string), index=False)\n",
    "except Exception as e:\n",
    "    driver.close()\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4a9a2-84c5-4609-8588-ca50cf0eb554",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHA TOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81cf584-e11e-471c-85dc-3707adface1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DET NOP DEN BKN CLE TOR ORL OKC LAL WAS CHA SAS\n",
    "DAL BOS CHI MIN PHI MEM LAL GSW SAC LAC CLE MIA HOU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
