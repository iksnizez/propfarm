{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2439018-9291-4dd7-bd78-1cbb79bd4a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time, re, os, json, mysql.connector\n",
    "#import mysql, pymysql, pyodbc\n",
    "#import sqlalchemy as sal\n",
    "#from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np\n",
    "#from bs4 import BeautifulSoup as bs\n",
    "from datetime import date\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "#importing credentials from txt file\n",
    "with open('../../../Notes-General/config.txt', 'r') as f:\n",
    "    creds = f.read()\n",
    "creds = json.loads(creds)\n",
    "\n",
    "# path to downloads folder\n",
    "download_path = creds['downloads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b3e20b9-2df1-44d0-b494-681697317ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TURNOVERS Message: Unable to locate element: .is-csv\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:180:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:392:5\n",
      "element.find/</<@chrome://remote/content/marionette/element.sys.mjs:275:16\n",
      "\n",
      "STLBLK Message: Unable to locate element: .is-csv\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:180:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:392:5\n",
      "element.find/</<@chrome://remote/content/marionette/element.sys.mjs:275:16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### using the save as button on the page to save the files individually.\n",
    "#### the rows of the tables that are not visible are hidden from HTML\n",
    "#### saving is the only way to get all the rows that I know at this time\n",
    "\n",
    "# path to webdriver for selenium\n",
    "service = Service(r\"..\\browser\\geckodriver.exe\")\n",
    "\n",
    "driver = webdriver.Firefox(service=service)\n",
    "waitTime = 10\n",
    "\n",
    "site = \"https://www.rotowire.com/betting/nba/player-props.php\"\n",
    "driver.get(site)\n",
    "\n",
    "# will be used to loop through the webpage\n",
    "data_prop_names = [\"PTS\",\"REB\",\"AST\",\n",
    "                   \"THREES\",\"BLK\",\"STL\",\n",
    "                   \"TURNOVERS\",\"PTSREBAST\",\"PTSREB\",\n",
    "                   \"PTSAST\",\"REBAST\",\"STLBLK\"]\n",
    "missing = []\n",
    "for i in range(len(data_prop_names)):\n",
    "# find the element in the source\n",
    "    try:\n",
    "        ele = driver.find_element(By.CSS_SELECTOR, \"div[data-prop={}]\".format(data_prop_names[i]))\n",
    "        # retrieve its page coords\n",
    "        loc = ele.location\n",
    "        #scroll to the location to activate the table creation\n",
    "        driver.execute_script(\"window.scrollTo(0, {});\".format(str(loc[\"y\"])))\n",
    "        # pause for data loading\n",
    "        time.sleep(3)\n",
    "        ###### save to csv \n",
    "        export_button = ele.find_element(By.CLASS_NAME, \"is-csv\")\n",
    "        export_button.click()\n",
    "    except Exception as e:\n",
    "        print(data_prop_names[i], e)\n",
    "        missing.append(i)\n",
    "        continue\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16fb77fd-0b21-4ab1-9565-d5501af48dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to use for renaming csv's\n",
    "columns = ['PLAYER', 'team', 'opp', 'dk_line', 'dk_oOdds', 'dk_uOdds',\n",
    "          'fd_line', 'fd_oOdds', 'fd_uOdds','m_line', 'm_oOdds', 'm_uOdds',\n",
    "          'pb_line', 'pb_oOdds', 'pb_uOdds']\n",
    "# will be used to get the correct file number when there are missing files\n",
    "count = 0\n",
    "# loop through each file to agg into a single data frame\n",
    "for i in range(0, len(data_prop_names)):\n",
    "    #uses the indices for the missing odds files\n",
    "    if i in missing:\n",
    "        continue\n",
    "    else:\n",
    "        stat = data_prop_names[i]\n",
    "        if i == 0:\n",
    "            path = download_path + \"nba-player-props-rotowire.csv\"\n",
    "            data = pd.read_csv(path, skiprows=1)\n",
    "            data.columns=columns\n",
    "            data['stat'] = stat\n",
    "        else:\n",
    "            count += 1\n",
    "            path = download_path + \"nba-player-props-rotowire({}).csv\"\n",
    "            temp = pd.read_csv(path.format(count), skiprows=1)\n",
    "            temp.columns=columns\n",
    "            temp['stat'] = stat\n",
    "            # concat data into main df    \n",
    "            data = pd.concat([data, temp])\n",
    "\n",
    "# using dk line as the default and averaging the other options when DK is not available\n",
    "data[\"line\"] = np.where(data[\"dk_line\"].isna(), \n",
    "                       data[[\"fd_line\",\"m_line\",\"pb_line\"]].mean(axis=1, skipna=True),\n",
    "                       data[\"dk_line\"])\n",
    "data[\"oOdds\"] = np.where(data[\"dk_oOdds\"].isna(), \n",
    "                       data[[\"fd_oOdds\",\"m_oOdds\",\"pb_oOdds\"]].mean(axis=1, skipna=True),\n",
    "                       data[\"dk_oOdds\"])\n",
    "data[\"uOdds\"] = np.where(data[\"dk_uOdds\"].isna(), \n",
    "                       data[[\"fd_uOdds\",\"m_uOdds\",\"pb_uOdds\"]].mean(axis=1, skipna=True),\n",
    "                       data[\"dk_uOdds\"])\n",
    "\n",
    "data = data[[\"PLAYER\", \"team\", \"stat\", \"line\", \"oOdds\", \"uOdds\"]]\n",
    "# adding the date of the odds\n",
    "data.loc[:,'date'] = date.today()  \n",
    "\n",
    "date_string = str(date.today())\n",
    "data.to_csv(\"../data/{}_odds.csv\".format(date_string), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2531c0-47fd-473e-80b6-816e20a62376",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a60a0a-9f28-4969-adec-dfc97487442f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### this facilitates programmatically accessing each prop table data\n",
    "### but only grabs the players visible on initial load. I don't know\n",
    "### how to scroll the div within the page yet.\n",
    "\n",
    "try:\n",
    "    # path to webdriver for selenium\n",
    "    service = Service(r\"..\\browser\\geckodriver.exe\")\n",
    "\n",
    "    driver = webdriver.Firefox(service=service)\n",
    "    waitTime = 10\n",
    "\n",
    "    site = \"https://www.rotowire.com/betting/nba/player-props.php\"\n",
    "    driver.get(site)\n",
    "\n",
    "\n",
    "    # will be used to loop through the webpage\n",
    "    data_prop_names = [\"PTS\",\"REB\",\"AST\",\"THREES\",\"BLK\",\"STL\",\"TURNOVERS\",\"PTSREBAST\",\"PTSREB\",\"PTSAST\",\"REBAST\",\"STLBLK\"]\n",
    "    for i in data_prop_names:\n",
    "    # find the element in the source\n",
    "        print(i)\n",
    "        ele = driver.find_element(By.CSS_SELECTOR, \"div[data-prop={}]\".format(i))\n",
    "        # retrieve its page coords\n",
    "        loc = ele.location\n",
    "        #scroll to the location to activate the table creation\n",
    "        driver.execute_script(\"window.scrollTo(0, {});\".format(str(loc[\"y\"])))\n",
    "        # pause for data loading\n",
    "        time.sleep(1)\n",
    "\n",
    "        #re-search for the element to get the data with the table populated\n",
    "        ele = driver.find_element(By.CSS_SELECTOR, \"div[data-prop={}]\".format(i))\n",
    "\n",
    "        names = ele.find_element(By.CLASS_NAME, \"webix_ss_left\")\n",
    "        remaining_data = ele.find_element(By.CLASS_NAME, \"webix_ss_center\")\n",
    "\n",
    "        ##### names #####\n",
    "        n = names.find_elements(By.CLASS_NAME, \"webix_cell  \")\n",
    "        PLAYER = []\n",
    "        stat = []\n",
    "        for j in n:\n",
    "            name = \" \".join(j.text.split()).strip()\n",
    "            PLAYER.append(name)\n",
    "            stat.append(i.lower())\n",
    "            #row = i.get_attribute('aria-rowindex')\n",
    "            #col = i.get_attribute('aria-colindex')\n",
    "\n",
    "        # pulling team and book line/odds data\n",
    "        cols = remaining_data.find_elements(By.CLASS_NAME, \"webix_column \")\n",
    "\n",
    "        ##### teams #####\n",
    "        teams = cols[0].find_elements(By.CLASS_NAME, \"webix_cell  \")\n",
    "        team = []\n",
    "        for t in teams:\n",
    "            team.append(t.text)\n",
    "\n",
    "        # this holds the location of each data point in remaining_data\n",
    "        # loc is the index and data will hold the actual line values\n",
    "        books = {\n",
    "            2:{\"data\":[]}, 3:{\"data\":[]}, 4:{\"data\":[]},\n",
    "            5:{\"data\":[]}, 6:{\"data\":[]}, 7:{\"data\":[]},\n",
    "            8:{\"data\":[]}, 9:{\"data\":[]}, 10:{\"data\":[]},\n",
    "            11:{\"data\":[]}, 12:{\"data\":[]}, 13:{\"data\":[]}\n",
    "        }\n",
    "\n",
    "        for j in books.keys():\n",
    "            #HTML hides HTML source data if it is not all visible on screen, pointsBET uOdds are offscreen\n",
    "            #I can't figure out FIrefox zoom with Selenium so I am skipping Pointsbet for this grouping\n",
    "            try:\n",
    "                temp_data = cols[j].find_elements(By.CLASS_NAME, \"webix_cell  \")\n",
    "                for h in temp_data:\n",
    "                    try:\n",
    "                        books[j]['data'].append(float(h.text))\n",
    "                    except:\n",
    "                        books[j]['data'].append(np.nan)\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        #using  PTS to start the main dataframe since each table is not sorted the same way\n",
    "        if i == \"PTS\":\n",
    "            # create main dataframe that will receive all the other data points\n",
    "            data = pd.DataFrame(list(zip(PLAYER, team, stat, \n",
    "                                 books[2]['data'], books[3]['data'], books[4]['data'], \n",
    "                                 books[5]['data'], books[6]['data'], books[7]['data'],\n",
    "                                 books[8]['data'], books[9]['data'], books[10]['data'],\n",
    "                                 books[11]['data'], books[12]['data'], books[13]['data'])),\n",
    "                        columns=[\"PLAYER\", \"team\", \"stat\", \n",
    "                          \"dk_line\", \"dk_oOdds\", \"dk_uOdds\",\n",
    "                          \"fd_line\", \"fd_oOdds\", \"fd_uOdds\",\n",
    "                          \"m_line\", \"m_oOdds\", \"m_uOdds\",\n",
    "                          \"pb_line\", \"pb_oOdds\", \"pb_uOdds\"])\n",
    "\n",
    "        else:\n",
    "            # combine all the data for the other stat lines into the main one\n",
    "            temp = pd.DataFrame(list(zip(PLAYER, team, stat, \n",
    "                                 books[2]['data'], books[3]['data'], books[4]['data'], \n",
    "                                 books[5]['data'], books[6]['data'], books[7]['data'],\n",
    "                                 books[8]['data'], books[9]['data'], books[10]['data'],\n",
    "                                 books[11]['data'], books[12]['data'], books[13]['data'])),\n",
    "                                columns=[\"PLAYER\", \"team\", \"stat\", \n",
    "                                  \"dk_line\", \"dk_oOdds\", \"dk_uOdds\",\n",
    "                                  \"fd_line\", \"fd_oOdds\", \"fd_uOdds\",\n",
    "                                  \"m_line\", \"m_oOdds\", \"m_uOdds\",\n",
    "                                  \"pb_line\", \"pb_oOdds\", \"pb_uOdds\"])\n",
    "            \n",
    "            data = pd.concat([data, temp])\n",
    "\n",
    "    # using dk line as the default and averaging the other options when DK is not available\n",
    "    data[\"line\"] = np.where(data[\"dk_line\"].isna(), \n",
    "                           data[[\"fd_line\",\"m_line\",\"pb_line\"]].mean(axis=1, skipna=True),\n",
    "                           data[\"dk_line\"])\n",
    "    data[\"oOdds\"] = np.where(data[\"dk_oOdds\"].isna(), \n",
    "                           data[[\"fd_oOdds\",\"m_oOdds\",\"pb_oOdds\"]].mean(axis=1, skipna=True),\n",
    "                           data[\"dk_oOdds\"])\n",
    "    data[\"uOdds\"] = np.where(data[\"dk_uOdds\"].isna(), \n",
    "                           data[[\"fd_uOdds\",\"m_uOdds\",\"pb_uOdds\"]].mean(axis=1, skipna=True),\n",
    "                           data[\"dk_uOdds\"])\n",
    "\n",
    "    data = data[[\"PLAYER\", \"team\", \"stat\", \"line\", \"oOdds\", \"uOdds\"]]\n",
    "    # adding the date of the odds\n",
    "    data.loc[:,'date'] = date.today()  \n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    # flattening all the stat lines for each player into a single line instead of multiple entries for each player\n",
    "    data = data.pivot(index=[\"PLAYER\", \"team\", \"date\"],\n",
    "                columns=[\"stat\"],\n",
    "                values=[\"line\", \"oOdds\",\"uOdds\"]\n",
    "    ).reset_index()\n",
    "    # combining the multi-column index names into a single name\n",
    "    data.columns   = ['_'.join(col) for col in data.columns.values]\n",
    "    \n",
    "    date_string = str(date.today())\n",
    "    data.to_csv(\"../output/{}_odds.csv\".format(date_string), index=False)\n",
    "except Exception as e:\n",
    "    driver.close()\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b80312-5179-4b55-a6a2-85f32ada10db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043e1583-4f72-4180-bff3-3e3824f154c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f0f95a-3f20-4c40-8e17-76505e41ee02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
